{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "patients = pd.read_csv(\"Patient Matching Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanPatients = patients.drop([\"MI\"], axis =1)\n",
    "cleanPatients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateAcc(acc):\n",
    "    if len(str(acc)) != 11:\n",
    "        return ''\n",
    "    else:\n",
    "        if acc[9] != \"-\":\n",
    "            return ''\n",
    "        else:\n",
    "            return acc\n",
    "\n",
    "cleanPatients[\"Patient Acct #\"] = cleanPatients[\"Patient Acct #\"].apply(validateAcc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanPatients.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_name = cleanPatients['First Name'].apply(lambda x: x.split())\n",
    "\n",
    "tokenized_name.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "tokenized_name = tokenized_name.apply(lambda x: [ps.stem(i) for i in x])\n",
    "\n",
    "tokenized_name.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_name.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def lowerstr(string):\n",
    "        return(str(string).lower())\n",
    "    \n",
    "cleanPatients[\"First Name\"] = cleanPatients['First Name'].apply(lowerstr)\n",
    "cleanPatients[\"Last Name\"] = cleanPatients['Last Name'].apply(lowerstr)\n",
    "\n",
    "cleanPatients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maps letters to phonetic groups\n",
    "soundex_map = { \n",
    "    **dict.fromkeys(\"BFPV\", '1'),\n",
    "    **dict.fromkeys(\"CGJKQSXZ\", '2'),\n",
    "    **dict.fromkeys(\"DT\", '3'),\n",
    "    **dict.fromkeys(\"L\", '4'),\n",
    "    **dict.fromkeys(\"MN\", '5'),\n",
    "    **dict.fromkeys(\"R\", '6'),\n",
    "    **dict.fromkeys(\"AEIOUHWY\", '.'),\n",
    "}\n",
    "\n",
    "soundex_map[\"J\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soundex(token):\n",
    "    \"\"\"Get the soundex code for the string\"\"\"\n",
    "    token = token.upper()\n",
    "\n",
    "    # first letter of input is always the first letter of soundex\n",
    "    soundex = token[0]\n",
    "    \n",
    "    for char in token[1:]:\n",
    "            code = soundex_map[char]\n",
    "            if code != soundex[-1]:\n",
    "                soundex += code\n",
    "\n",
    "    # remove vowels and 'H', 'W' and 'Y' from soundex\n",
    "    soundex = soundex.replace(\".\", \"\")\n",
    "    \n",
    "    # trim or pad to make soundex a 4-character code\n",
    "    soundex = soundex[:4].ljust(4, \"0\")\n",
    "        \n",
    "    return soundex\n",
    "\n",
    "get_soundex(\"Maine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://gist.github.com/rogerallen/1583593\n",
    "us_state_abbrev = {\n",
    "    'Alabama': 'AL',\n",
    "    'Alaska': 'AK',\n",
    "    'American Samoa': 'AS',\n",
    "    'Arizona': 'AZ',\n",
    "    'Arkansas': 'AR',\n",
    "    'California': 'CA',\n",
    "    'Colorado': 'CO',\n",
    "    'Connecticut': 'CT',\n",
    "    'Delaware': 'DE',\n",
    "    'District of Columbia': 'DC',\n",
    "    'Florida': 'FL',\n",
    "    'Georgia': 'GA',\n",
    "    'Guam': 'GU',\n",
    "    'Hawaii': 'HI',\n",
    "    'Idaho': 'ID',\n",
    "    'Illinois': 'IL',\n",
    "    'Indiana': 'IN',\n",
    "    'Iowa': 'IA',\n",
    "    'Kansas': 'KS',\n",
    "    'Kentucky': 'KY',\n",
    "    'Louisiana': 'LA',\n",
    "    'Maine': 'ME',\n",
    "    'Maryland': 'MD',\n",
    "    'Massachusetts': 'MA',\n",
    "    'Michigan': 'MI',\n",
    "    'Minnesota': 'MN',\n",
    "    'Mississippi': 'MS',\n",
    "    'Missouri': 'MO',\n",
    "    'Montana': 'MT',\n",
    "    'Nebraska': 'NE',\n",
    "    'Nevada': 'NV',\n",
    "    'New Hampshire': 'NH',\n",
    "    'New Jersey': 'NJ',\n",
    "    'New Mexico': 'NM',\n",
    "    'New York': 'NY',\n",
    "    'North Carolina': 'NC',\n",
    "    'North Dakota': 'ND',\n",
    "    'Northern Mariana Islands':'MP',\n",
    "    'Ohio': 'OH',\n",
    "    'Oklahoma': 'OK',\n",
    "    'Oregon': 'OR',\n",
    "    'Pennsylvania': 'PA',\n",
    "    'Puerto Rico': 'PR',\n",
    "    'Rhode Island': 'RI',\n",
    "    'South Carolina': 'SC',\n",
    "    'South Dakota': 'SD',\n",
    "    'Tennessee': 'TN',\n",
    "    'Texas': 'TX',\n",
    "    'Utah': 'UT',\n",
    "    'Vermont': 'VT',\n",
    "    'Virgin Islands': 'VI',\n",
    "    'Virginia': 'VA',\n",
    "    'Washington': 'WA',\n",
    "    'West Virginia': 'WV',\n",
    "    'Wisconsin': 'WI',\n",
    "    'Wyoming': 'WY'\n",
    "}\n",
    "\n",
    "abbrev_us_state = dict(map(reversed, us_state_abbrev.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_soundex(\"Main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_soundex(\"Sutton\"), get_soundex(\"Suttin\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_state(state):\n",
    "    if state in us_state_abbrev:\n",
    "        return us_state_abbrev[state]\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_state_code(state):\n",
    "    if state in abbrev_us_state:\n",
    "        return abbrev_us_state[state]\n",
    "    \n",
    "    return state\n",
    "\n",
    "cleanPatients[\"Current State\"] = cleanPatients[\"Current State\"].apply(convert_state_code)\n",
    "cleanPatients[\"Previous State\"] = cleanPatients[\"Previous State\"].apply(convert_state_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_state(state):\n",
    "    if state in us_state_abbrev:\n",
    "        return us_state_abbrev[state]\n",
    "    \n",
    "    return state\n",
    "\n",
    "cleanPatients[\"Current State\"] = cleanPatients[\"Current State\"].apply(convert_state)\n",
    "cleanPatients[\"Previous State\"] = cleanPatients[\"Previous State\"].apply(convert_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanPatients[\"Current State\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanPatients[\"Previous State\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanPatients['Current Street 2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def convert_address_2(address):\n",
    "    address = str(address).lower()\n",
    "    apt_no = re.match(\"(apt|apartment)?\\s*#?\\s*(\\d+)\", address)\n",
    "    \n",
    "    return apt_no.group(2) if apt_no else ''\n",
    "\n",
    "cleanPatients['Current Street 2'] = cleanPatients['Current Street 2'].apply(convert_address_2)\n",
    "cleanPatients['Current Street 2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanPatients[\"First Name\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanPatients['Previous Street 2'] = cleanPatients['Previous Street 2'].apply(convert_address_2)\n",
    "cleanPatients['Previous Street 2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "street_abv = {\n",
    "    \"ave\": \"avenue\",\n",
    "    \"ln\": \"lane\",\n",
    "    \"st\": \"street\",\n",
    "    \"dr\": \"drive\",\n",
    "    \"rd\": \"road\",\n",
    "    \"cir\": \"circle\",\n",
    "    \"pt\": \"point\",\n",
    "    \"pkway\": \"parkway\",\n",
    "    \"ct\": \"court\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def clean_address(address):\n",
    "    address = str(address).lower()\n",
    "    table = str.maketrans(dict.fromkeys(string.punctuation))\n",
    "    \n",
    "    address = address.translate(table)\n",
    "    \n",
    "    if address == 'nan':\n",
    "        return ''\n",
    "    \n",
    "    tokens = address.split()\n",
    "    if len(tokens) >= 3:\n",
    "        if tokens[-1] in street_abv:\n",
    "            tokens[-1] = street_abv[tokens[-1]]\n",
    "        return \" \".join(tokens)\n",
    "    \n",
    "    return address\n",
    "\n",
    "cleanPatients[\"Current Street 1\"] = cleanPatients[\"Current Street 1\"].apply(clean_address)\n",
    "print(cleanPatients[\"Current Street 1\"].value_counts().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanPatients[\"Previous Street 1\"] = cleanPatients[\"Previous Street 1\"].apply(clean_address)\n",
    "print(cleanPatients[\"Previous Street 1\"].value_counts().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sex(sex):\n",
    "    sex = str(sex).lower()\n",
    "    \n",
    "    if sex and sex[0] == 'm':\n",
    "        return 'm'\n",
    "    elif sex and sex[0] == 'f':\n",
    "        return 'f'\n",
    "    \n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanPatients[\"Sex\"] = cleanPatients[\"Sex\"].apply(clean_sex)\n",
    "\n",
    "cleanPatients[\"Sex\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maps letters to phonetic groups\n",
    "soundex_map = { \n",
    "    **dict.fromkeys(\"BFPV\", '1'),\n",
    "    **dict.fromkeys(\"CGJKQSXZ\", '2'),\n",
    "    **dict.fromkeys(\"DT\", '3'),\n",
    "    **dict.fromkeys(\"L\", '4'),\n",
    "    **dict.fromkeys(\"MN\", '5'),\n",
    "    **dict.fromkeys(\"R\", '6'),\n",
    "    **dict.fromkeys(\"AEIOUHWY\", '.'),\n",
    "}\n",
    "\n",
    "soundex_map[\"J\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soundex(token):\n",
    "    \"\"\"Get the soundex code for the string\"\"\"\n",
    "    token = token.upper()\n",
    "\n",
    "    # first letter of input is always the first letter of soundex\n",
    "    soundex = token[0]\n",
    "    \n",
    "    for char in token[1:]:\n",
    "            code = soundex_map[char]\n",
    "            if code != soundex[-1]:\n",
    "                soundex += code\n",
    "\n",
    "    # remove vowels and 'H', 'W' and 'Y' from soundex\n",
    "    soundex = soundex.replace(\".\", \"\")\n",
    "    \n",
    "    # trim or pad to make soundex a 4-character code\n",
    "    soundex = soundex[:4].ljust(4, \"0\")\n",
    "        \n",
    "    return soundex\n",
    "\n",
    "get_soundex(\"Maine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_soundex(\"Mervin\"))\n",
    "print(get_soundex(\"Mikel\"))\n",
    "print(get_soundex(\"Mikel\"))\n",
    "print(get_soundex(\"Michael\"))\n",
    "print(get_soundex(\"Mike\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soundex_map[\"Z\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from metaphone import doublemetaphone\n",
    "from enum import Enum\n",
    "\n",
    "class Threshold(Enum):\n",
    "    WEAK = 0\n",
    "    NORMAL = 1\n",
    "    STRONG = 2\n",
    "\n",
    "def double_metaphone(value):\n",
    "    #print(doublemetaphone(value))\n",
    "    return doublemetaphone(value)\n",
    "\n",
    "#(Primary Key = Primary Key) = Strongest Match\n",
    "#(Secondary Key = Primary Key) = Normal Match\n",
    "#(Primary Key = Secondary Key) = Normal Match\n",
    "#(Alternate Key = Alternate Key) = Minimal Match\n",
    "def double_metaphone_compare(tuple1,tuple2,threshold):\n",
    "    if threshold == Threshold.WEAK:\n",
    "        if tuple1[1] == tuple2[1]:\n",
    "            return True\n",
    "    elif threshold == Threshold.NORMAL:\n",
    "        if tuple1[0] == tuple2[1] or tuple1[1] == tuple2[0]:\n",
    "            return True\n",
    "    else:\n",
    "        if tuple1[0] == tuple2[0]:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMetaphone(string):\n",
    "    met = double_metaphone(string)\n",
    "    return met[0]\n",
    "cleanPatients[\"metFirst\"] = cleanPatients[\"First Name\"].apply(getMetaphone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanPatients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanPatients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanPatients[\"names\"] = cleanPatients['First Name'].fillna('') + ' ' + cleanPatients['Last Name'].fillna('')\n",
    "cleanPatients[\"names\"] = cleanPatients['names'].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import isnan\n",
    "def convert_zip(z):\n",
    "    if isnan(z):\n",
    "        return ''\n",
    "    \n",
    "    return str(int(z))\n",
    "\n",
    "    \n",
    "cleanPatients['Current Zip Code'] = cleanPatients['Current Zip Code'].apply(convert_zip)\n",
    "cleanPatients['Current Zip Code'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanPatients[\"address\"] = cleanPatients['Current Street 1'].fillna('') + ' ' + cleanPatients['Current Street 2'] + ' '\\\n",
    "    + cleanPatients['Current City'].fillna('') + ' ' + cleanPatients['Current State'].fillna('') + ' '\\\n",
    "    + cleanPatients['Current Zip Code']\n",
    "cleanPatients[\"address\"] = cleanPatients[\"address\"].apply(lowerstr)\n",
    "cleanPatients[\"address\"] = cleanPatients['address'].apply(lambda x: x.strip())\n",
    "cleanPatients.head(70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dob(date):\n",
    "    return date.replace('/', '')\n",
    "\n",
    "cleanPatients['Date of Birth'] = cleanPatients['Date of Birth'].apply(clean_dob)\n",
    "cleanPatients['Date of Birth'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "import numpy as np\n",
    "def compare(a,b):\n",
    "    scores = []\n",
    "    count = 0\n",
    "    if a[\"names\"] and b[\"names\"]:\n",
    "        a_met = double_metaphone(a[\"names\"])\n",
    "        b_met = double_metaphone(b[\"names\"])\n",
    "        \n",
    "        name_scores = []\n",
    "        if double_metaphone_compare(a_met, b_met, Threshold.STRONG):\n",
    "            name_scores.append(100)\n",
    "        \n",
    "        name_scores.append(fuzz.token_sort_ratio(a[\"names\"], b[\"names\"]))\n",
    "        scores.append(max(name_scores))\n",
    "    \n",
    "    \n",
    "        \n",
    "    if b[\"address\"] == \"\":\n",
    "        addressScore = 50\n",
    "        scores.append(addressScore)\n",
    "    elif a[\"address\"] and b[\"address\"]:\n",
    "        addressScore = fuzz.token_sort_ratio(a[\"address\"], b[\"address\"])\n",
    "        if addressScore > 80:\n",
    "            scores.append(addressScore)\n",
    "        elif a[\"Current Street 1\"] and b[\"Current Street 1\"]:\n",
    "            scores.append(min(addressScore - 20 ,fuzz.token_sort_ratio(a[\"Current Street 1\"], b[\"Current Street 1\"])))\n",
    "   \n",
    "        \n",
    "    \n",
    "    if a[\"Sex\"] and b[\"Sex\"]:\n",
    "        if a[\"Sex\"] == b[\"Sex\"]:\n",
    "            scores.append(90)\n",
    "        else:\n",
    "            scores.append(60)\n",
    "        \n",
    "    if a[\"Date of Birth\"] and b[\"Date of Birth\"]:\n",
    "        date_score = fuzz.token_sort_ratio(a[\"Date of Birth\"], b[\"Date of Birth\"])\n",
    "        if (date_score < 60):\n",
    "            date_score = 0\n",
    "    \n",
    "    \n",
    "        scores.append(date_score)\n",
    "        \n",
    "#     if a[\"Patient Acct #\"] and b[\"Patient Acct #\"]:\n",
    "#         scores.append(fuzz.token_sort_ratio(a[\"Patient Acct #\"], b[\"Patient Acct #\"])\n",
    "\n",
    "#     if(len(scores) < 50):\n",
    "    print(scores)    \n",
    "    return np.mean(scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzz.token_sort_ratio('4211950', '3191960')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cleanPatients[\"assigned\"] = 0\n",
    "cleanPatients[\"groupno\"] = -1\n",
    "groups = []\n",
    "print(groups)\n",
    "for index, row in cleanPatients.iterrows():\n",
    "    if row['assigned'] == 1:\n",
    "        continue\n",
    "    else:\n",
    "        for group_index, x in enumerate(groups):\n",
    "            temp = compare(cleanPatients.loc[x[0]], row)\n",
    "            if len(x)>1:\n",
    "                temp = max(temp, compare(cleanPatients.loc[x[1]], row))\n",
    "            #print(f'fuzz for {x[0]} and {row[\"names\"]} = {temp},  index is {index}')\n",
    "            if(temp > 86):\n",
    "                cleanPatients.loc[index,\"groupno\"] = group_index+1\n",
    "                groups[group_index].append(index)\n",
    "                break\n",
    "        else:\n",
    "            groups.append([index])\n",
    "            cleanPatients.loc[index,\"groupno\"] = len(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzz.token_sort_ratio(\"may field\",\"field may\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanPatients.head(191)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_groups = []\n",
    "for i in range(1,66):\n",
    "    current_group = []\n",
    "    for index, row in cleanPatients.loc[cleanPatients['GroupID'] == i].iterrows():\n",
    "        current_group.append(index)\n",
    "    true_groups.append(current_group)\n",
    "\n",
    "for i, true_group in enumerate(true_groups):\n",
    "    print(true_group, groups[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, true_group in enumerate(true_groups):\n",
    "    if true_group not in groups:\n",
    "        if i < len(groups):\n",
    "            print(true_group, groups[i])\n",
    "        else:\n",
    "            print(true_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
